{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiWorkerMirroredStrategy on Hopsworks\n",
    "---\n",
    "\n",
    "<font color='red'> <h3>Tested with TensorFlow 2.2.0</h3></font>\n",
    "\n",
    "<p>\n",
    "<h1>Machine Learning on <a href=\"https://github.com/logicalclocks/hopsworks\">Hopsworks\n",
    "</a></h1> \n",
    "</p>\n",
    "\n",
    "![hops.png](../../../images/hops.png)\n",
    "\n",
    "## The `hops` python module\n",
    "\n",
    "`hops` is a helper library for Hops that facilitates development by hiding the complexity of running applications and iteracting with services.\n",
    "\n",
    "Have a feature request or encountered an issue? Please let us know on <a href=\"https://github.com/logicalclocks/hops-util-py\">github</a>.\n",
    "\n",
    "### Using the `experiment` module\n",
    "\n",
    "To be able to run your Machine Learning code in Hopsworks, the code for the whole program needs to be provided and put inside a wrapper function. Everything, from importing libraries to reading data and defining the model and running the program needs to be put inside a wrapper function.\n",
    "\n",
    "The `experiment` module provides an api to Python programs such as TensorFlow, Keras and PyTorch on a Hopsworks on any number of machines and GPUs.\n",
    "\n",
    "An Experiment could be a single Python program, which we refer to as an **Experiment**. \n",
    "\n",
    "Grid search or genetic hyperparameter optimization such as differential evolution which runs several Experiments in parallel, which we refer to as **Parallel Experiment**. \n",
    "\n",
    "ParameterServerStrategy, CollectiveAllReduceStrategy and MultiworkerMirroredStrategy making multi-machine/multi-gpu training as simple as invoking a function for orchestration. This mode is referred to as **Distributed Training**.\n",
    "\n",
    "### Using the `tensorboard` module\n",
    "The `tensorboard` module allow us to get the log directory for summaries and checkpoints to be written to the TensorBoard we will see in a bit. The only function that we currently need to call is `tensorboard.logdir()`, which returns the path to the TensorBoard log directory. Furthermore, the content of this directory will be put in as a Dataset in your project's Experiments folder.\n",
    "\n",
    "The directory could in practice be used to store other data that should be accessible after the experiment is finished.\n",
    "```python\n",
    "# Use this module to get the TensorBoard logdir\n",
    "from hops import tensorboard\n",
    "tensorboard_logdir = tensorboard.logdir()\n",
    "```\n",
    "\n",
    "### Using the `hdfs` module\n",
    "The `hdfs` module provides a method to get the path in HopsFS where your data is stored, namely by calling `hdfs.project_path()`. The path resolves to the root path for your project, which is the view that you see when you click `Data Sets` in HopsWorks. To point where your actual data resides in the project you to append the full path from there to your Dataset. For example if you create a mnist folder in your Resources Dataset, the path to the mnist data would be `hdfs.project_path() + 'Resources/mnist'`\n",
    "\n",
    "```python\n",
    "# Use this module to get the path to your project in HopsFS, then append the path to your Dataset in your project\n",
    "from hops import hdfs\n",
    "project_path = hdfs.project_path()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Downloading the mnist dataset to the current working directory\n",
    "from hops import hdfs\n",
    "mnist_hdfs_path = hdfs.project_path() + \"Resources/mnist\"\n",
    "local_mnist_path = hdfs.copy_to_local(mnist_hdfs_path)\n",
    "```\n",
    "\n",
    "### Documentation\n",
    "See the following links to learn more about running experiments in Hopsworks\n",
    "\n",
    "- <a href=\"https://hopsworks.readthedocs.io/en/latest/hopsml/experiment.html\">Learn more about experiments</a>\n",
    "<br>\n",
    "- <a href=\"https://hopsworks.readthedocs.io/en/latest/hopsml/hopsML.html\">Building End-To-End pipelines</a>\n",
    "<br>\n",
    "- Give us a star, create an issue or a feature request on  <a href=\"https://github.com/logicalclocks/hopsworks\">Hopsworks github</a>\n",
    "\n",
    "### Managing experiments\n",
    "Experiments service provides a unified view of all the experiments run using the `experiment` module.\n",
    "<br>\n",
    "As demonstrated in the gif it provides general information about the experiment and the resulting metric. Experiments can be visualized meanwhile or after training in a TensorBoard.\n",
    "<br>\n",
    "<br>\n",
    "![Image7-Monitor.png](../../../images/experiments.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>38</td><td>application_1586279424915_0039</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8088/proxy/application_1586279424915_0039/\">Link</a></td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8042/node/containerlogs/container_e01_1586279424915_0039_01_000001/demo_deep_learning_admin000__meb10000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, hopsworks0.logicalclocks.com, executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 196, in parse_entity\n",
      "    original_source = inspect_utils.getimmediatesource(entity)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py\", line 147, in getimmediatesource\n",
      "    lines, lnum = inspect.findsource(obj)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/inspect.py\", line 786, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 538, in converted_call\n",
      "    converted_f = conversion.convert(target_entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 360, in convert\n",
      "    free_nonglobal_var_names)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 275, in _convert_with_cache\n",
      "    entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 511, in convert_entity_to_ast\n",
      "    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 673, in convert_func_to_ast\n",
      "    node, source = parser.parse_entity(f, future_features=future_features)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 204, in parse_entity\n",
      "    ' @tf.autograph.do_not_convert. Original error: {}'.format(entity, e))\n",
      "ValueError: Unable to locate the source code of <function multi_worker_mirrored_training.<locals>.input_fn.<locals>._normalize_img at 0x7f07a8068730>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n",
      "    process()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n",
      "    serializer.dump_stream(func(split_index, iterator), outfile)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 352, in func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 801, in func\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/hops/experiment_impl/distribute/mirrored.py\", line 149, in _wrapper_fun\n",
      "    retval = map_fun()\n",
      "  File \"<stdin>\", line 125, in multi_worker_mirrored_training\n",
      "  File \"<stdin>\", line 81, in input_fn\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1628, in map\n",
      "    preserve_cardinality=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4013, in __init__\n",
      "    use_legacy_function=use_legacy_function)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3221, in __init__\n",
      "    self._function = wrapper_fn.get_concrete_function()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2532, in get_concrete_function\n",
      "    *args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2496, in _get_concrete_function_garbage_collected\n",
      "    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3214, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3156, in _wrapper_helper\n",
      "    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 262, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 580, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 346, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"<stdin>\", line 61, in _normalize_img\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n",
      "    x = ops.convert_to_tensor(x, name=\"x\")\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1341, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 321, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 262, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_impl\n",
      "    allow_broadcast=allow_broadcast))\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 439, in make_tensor_proto\n",
      "    raise ValueError(\"None values not supported.\")\n",
      "ValueError: None values not supported.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n",
      "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 196, in parse_entity\n",
      "    original_source = inspect_utils.getimmediatesource(entity)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py\", line 147, in getimmediatesource\n",
      "    lines, lnum = inspect.findsource(obj)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/inspect.py\", line 786, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 538, in converted_call\n",
      "    converted_f = conversion.convert(target_entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 360, in convert\n",
      "    free_nonglobal_var_names)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 275, in _convert_with_cache\n",
      "    entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 511, in convert_entity_to_ast\n",
      "    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 673, in convert_func_to_ast\n",
      "    node, source = parser.parse_entity(f, future_features=future_features)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 204, in parse_entity\n",
      "    ' @tf.autograph.do_not_convert. Original error: {}'.format(entity, e))\n",
      "ValueError: Unable to locate the source code of <function multi_worker_mirrored_training.<locals>.input_fn.<locals>._normalize_img at 0x7f07a8068730>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n",
      "    process()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n",
      "    serializer.dump_stream(func(split_index, iterator), outfile)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 352, in func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 801, in func\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/hops/experiment_impl/distribute/mirrored.py\", line 149, in _wrapper_fun\n",
      "    retval = map_fun()\n",
      "  File \"<stdin>\", line 125, in multi_worker_mirrored_training\n",
      "  File \"<stdin>\", line 81, in input_fn\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1628, in map\n",
      "    preserve_cardinality=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4013, in __init__\n",
      "    use_legacy_function=use_legacy_function)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3221, in __init__\n",
      "    self._function = wrapper_fn.get_concrete_function()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2532, in get_concrete_function\n",
      "    *args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2496, in _get_concrete_function_garbage_collected\n",
      "    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3214, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3156, in _wrapper_helper\n",
      "    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 262, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 580, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 346, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"<stdin>\", line 61, in _normalize_img\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n",
      "    x = ops.convert_to_tensor(x, name=\"x\")\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1341, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 321, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 262, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_impl\n",
      "    allow_broadcast=allow_broadcast))\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 439, in make_tensor_proto\n",
      "    raise ValueError(\"None values not supported.\")\n",
      "ValueError: None values not supported.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/hops/experiment.py\", line 591, in mirrored\n",
      "    logdir, return_dict = mirrored_impl._run(sc, map_fun, run_id, local_logdir=local_logdir, name=name, evaluator=evaluator)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/hops/experiment_impl/distribute/mirrored.py\", line 47, in _run\n",
      "    nodeRDD.foreachPartition(_prepare_func(app_id, run_id, map_fun, local_logdir, server_addr, evaluator, util.num_executors()))\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 806, in foreachPartition\n",
      "    self.mapPartitions(func).count()  # Force evaluation\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1055, in count\n",
      "    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1046, in sum\n",
      "    return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 917, in fold\n",
      "    vals = self.mapPartitions(func).collect()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 816, in collect\n",
      "    sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())\n",
      "  File \"/srv/hops/spark/python/lib/py4j-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/srv/hops/spark/python/lib/py4j-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, hopsworks0.logicalclocks.com, executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 196, in parse_entity\n",
      "    original_source = inspect_utils.getimmediatesource(entity)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py\", line 147, in getimmediatesource\n",
      "    lines, lnum = inspect.findsource(obj)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/inspect.py\", line 786, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 538, in converted_call\n",
      "    converted_f = conversion.convert(target_entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 360, in convert\n",
      "    free_nonglobal_var_names)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 275, in _convert_with_cache\n",
      "    entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 511, in convert_entity_to_ast\n",
      "    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 673, in convert_func_to_ast\n",
      "    node, source = parser.parse_entity(f, future_features=future_features)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 204, in parse_entity\n",
      "    ' @tf.autograph.do_not_convert. Original error: {}'.format(entity, e))\n",
      "ValueError: Unable to locate the source code of <function multi_worker_mirrored_training.<locals>.input_fn.<locals>._normalize_img at 0x7f07a8068730>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n",
      "    process()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n",
      "    serializer.dump_stream(func(split_index, iterator), outfile)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 352, in func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 801, in func\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/hops/experiment_impl/distribute/mirrored.py\", line 149, in _wrapper_fun\n",
      "    retval = map_fun()\n",
      "  File \"<stdin>\", line 125, in multi_worker_mirrored_training\n",
      "  File \"<stdin>\", line 81, in input_fn\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1628, in map\n",
      "    preserve_cardinality=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4013, in __init__\n",
      "    use_legacy_function=use_legacy_function)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3221, in __init__\n",
      "    self._function = wrapper_fn.get_concrete_function()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2532, in get_concrete_function\n",
      "    *args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2496, in _get_concrete_function_garbage_collected\n",
      "    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3214, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3156, in _wrapper_helper\n",
      "    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 262, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 580, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 346, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"<stdin>\", line 61, in _normalize_img\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n",
      "    x = ops.convert_to_tensor(x, name=\"x\")\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1341, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 321, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 262, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_impl\n",
      "    allow_broadcast=allow_broadcast))\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 439, in make_tensor_proto\n",
      "    raise ValueError(\"None values not supported.\")\n",
      "ValueError: None values not supported.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n",
      "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 196, in parse_entity\n",
      "    original_source = inspect_utils.getimmediatesource(entity)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py\", line 147, in getimmediatesource\n",
      "    lines, lnum = inspect.findsource(obj)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/inspect.py\", line 786, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 538, in converted_call\n",
      "    converted_f = conversion.convert(target_entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 360, in convert\n",
      "    free_nonglobal_var_names)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 275, in _convert_with_cache\n",
      "    entity, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 511, in convert_entity_to_ast\n",
      "    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 673, in convert_func_to_ast\n",
      "    node, source = parser.parse_entity(f, future_features=future_features)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/parser.py\", line 204, in parse_entity\n",
      "    ' @tf.autograph.do_not_convert. Original error: {}'.format(entity, e))\n",
      "ValueError: Unable to locate the source code of <function multi_worker_mirrored_training.<locals>.input_fn.<locals>._normalize_img at 0x7f07a8068730>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n",
      "    process()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n",
      "    serializer.dump_stream(func(split_index, iterator), outfile)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2499, in pipeline_func\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 352, in func\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 801, in func\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/hops/experiment_impl/distribute/mirrored.py\", line 149, in _wrapper_fun\n",
      "    retval = map_fun()\n",
      "  File \"<stdin>\", line 125, in multi_worker_mirrored_training\n",
      "  File \"<stdin>\", line 81, in input_fn\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1628, in map\n",
      "    preserve_cardinality=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4013, in __init__\n",
      "    use_legacy_function=use_legacy_function)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3221, in __init__\n",
      "    self._function = wrapper_fn.get_concrete_function()\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2532, in get_concrete_function\n",
      "    *args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2496, in _get_concrete_function_garbage_collected\n",
      "    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3214, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3156, in _wrapper_helper\n",
      "    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 262, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 580, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 346, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"<stdin>\", line 61, in _normalize_img\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n",
      "    x = ops.convert_to_tensor(x, name=\"x\")\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1341, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 321, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 262, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_impl\n",
      "    allow_broadcast=allow_broadcast))\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/demo_deep_learning_admin000/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 439, in make_tensor_proto\n",
      "    raise ValueError(\"None values not supported.\")\n",
      "ValueError: None values not supported.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def multi_worker_mirrored_training():\n",
    "\n",
    "    import sys\n",
    "    \n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    from hops import tensorboard\n",
    "    from hops import devices\n",
    "    from hops import hdfs\n",
    "    \n",
    "    import pydoop.hdfs as pydoop\n",
    "    \n",
    "    data_dir = hdfs.project_path()\n",
    "    train_filenames = pydoop.path.abspath(data_dir + \"TourData/mnist/train/df-mnist_train.tfrecord\")\n",
    "    train_filenames = tf.io.gfile.glob(train_filenames + \"/part-r-*\")\n",
    "    validation_filenames = pydoop.path.abspath(data_dir + \"TourData/mnist/validation/df-mnist_test.tfrecord\")\n",
    "    validation_filenames = tf.io.gfile.glob(validation_filenames + \"/part-r-*\")\n",
    "    \n",
    "    # Define distribution strategy\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(communication=tf.distribute.experimental.CollectiveCommunication.NCCL)\n",
    "\n",
    "    epochs=30 \n",
    "    steps_per_epoch=5\n",
    "    validation_steps=2          \n",
    "    \n",
    "    batch_size_per_replica = 32\n",
    "    batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n",
    "    shuffle_size = batch_size * 4\n",
    "    \n",
    "    num_classes = 10\n",
    "    kernel = 3\n",
    "    pool = 2\n",
    "    dropout = 0.5    \n",
    "\n",
    "    \n",
    "    # Input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    def input_fn(filenames, batch_size):\n",
    "      \n",
    "    \n",
    "      def _parser(serialized_example):\n",
    "            \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "            features = tf.io.parse_single_example(\n",
    "                serialized_example,\n",
    "                features={\n",
    "                    'image_raw': tf.io.FixedLenFeature([img_rows * img_cols], tf.float32),                    \n",
    "                    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                })\n",
    "            \n",
    "            image = features['image_raw']\n",
    "            label = features['label']   \n",
    "                \n",
    "            return image, label\n",
    "      \n",
    "    \n",
    "      def _normalize_img(image, label):\n",
    "            \"\"\"Normalizes images\"\"\"\n",
    "            image = tf.cast(image, tf.float32) / 255\n",
    "            label = tf.cast(label, tf.int32)        \n",
    "            return image, label\n",
    "\n",
    "      def _reshape_img(image, label):\n",
    "        image = tf.reshape(image, [28, 28, 1])\n",
    "        # label = tf.one_hot(label, num_classes)\n",
    "        return image, label\n",
    "        \n",
    "        \n",
    "      # Import MNIST data\n",
    "      dataset = tf.data.TFRecordDataset(filenames)\n",
    "        \n",
    "      # Map the parser over dataset, and batch results by up to batch_size\n",
    "      dataset = dataset.map(_parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "#      dataset = dataset.map(\n",
    "#        _normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        \n",
    "      dataset = dataset.map(\n",
    "        _reshape_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      dataset = dataset.repeat(epochs * steps_per_epoch)\n",
    "      dataset = dataset.cache()\n",
    "      dataset = dataset.shuffle(shuffle_size)\n",
    "      dataset = dataset.batch(batch_size)   \n",
    "  \n",
    "      dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  #    dataset = strategy.experimental_distribute_dataset(dataset)         \n",
    "\n",
    "      return dataset\n",
    "    \n",
    "    model_dir = tensorboard.logdir()\n",
    "    print('Using %s to store checkpoints.' % model_dir)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Define a Keras Model.\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(32, kernel_size=kernel, padding='same',\n",
    "                            activation='relu',\n",
    "                             input_shape=input_shape))\n",
    "        model.add(tf.keras.layers.Conv2D(64, kernel,  padding='same',activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=pool))\n",
    "        model.add(tf.keras.layers.Dropout(dropout))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(dropout))\n",
    "        model.add(tf.keras.layers.Dense(num_classes))\n",
    "\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "            metrics=['accuracy'],\n",
    "        )\n",
    "        \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=model_dir),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=model_dir),\n",
    "    ]\n",
    "    \n",
    "    model.fit(input_fn(train_filenames, batch_size), \n",
    "        verbose=0, \n",
    "        epochs=epochs, \n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=input_fn(validation_filenames, batch_size),\n",
    "        validation_steps=validation_steps,      \n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    score = model.evaluate(input_fn(validation_filenames, batch_size), steps=1)\n",
    "    return {'accuracy': score[1]}    \n",
    "\n",
    "from hops import experiment\n",
    "experiment.mirrored(multi_worker_mirrored_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read32(bytestream):\n",
    "  dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n",
    "  return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "def extract_images(f):\n",
    "  \"\"\"\n",
    "  Extract the images into a 4D uint8 numpy array.\n",
    "  \"\"\"\n",
    "  print('Extracting', f.name)\n",
    "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "    magic = _read32(bytestream)\n",
    "    if magic != 2051:\n",
    "      raise ValueError('Invalid magic number %d in MNIST image file: %s' %\n",
    "                       (magic, f.name))\n",
    "    num_images = _read32(bytestream)\n",
    "    rows = _read32(bytestream)\n",
    "    cols = _read32(bytestream)\n",
    "    buf = bytestream.read(rows * cols * num_images)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    data = data.reshape(num_images, rows, cols, 1)\n",
    "    return data\n",
    "\n",
    "def extract_labels(f, one_hot=False, num_classes=10):\n",
    "  \"\"\"\n",
    "  Extract the labels into a 1D uint8 numpy array.\n",
    "  \"\"\"\n",
    "  print('Extracting', f.name)\n",
    "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "    magic = _read32(bytestream)\n",
    "    if magic != 2049:\n",
    "      raise ValueError('Invalid magic number %d in MNIST label file: %s' %\n",
    "                       (magic, f.name))\n",
    "    num_items = _read32(bytestream)\n",
    "    buf = bytestream.read(num_items)\n",
    "    labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(images_file, labels_file):\n",
    "  \"\"\"Download and parse MNIST dataset.\"\"\"\n",
    "\n",
    "  #images_file = download(images_file)\n",
    "  #labels_file = download(abels_file)\n",
    "\n",
    "  with tf.io.gfile.GFile(images_file, 'rb') as f:\n",
    "    images = extract_images(f)\n",
    "    images = images.reshape(images.shape[0], images.shape[1] * images.shape[2])\n",
    "    images = images.astype(numpy.float32)\n",
    "    images = numpy.multiply(images, 1.0 / 255.0)\n",
    "    \n",
    "  with tf.io.gfile.GFile(labels_file, 'rb') as f:\n",
    "    labels = extract_labels(f)\n",
    "\n",
    "  return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/train-labels-idx1-ubyte.gz"
     ]
    }
   ],
   "source": [
    "import pydoop.hdfs as pydoop\n",
    "\n",
    "a = pydoop.path.abspath(\"hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/t10k-images-idx3-ubyte.gz\")\n",
    "b = pydoop.path.abspath(\"hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "c = pydoop.path.abspath(\"hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/t10k-images-idx3-ubyte.gz\")\n",
    "d = pydoop.path.abspath(\"hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "train_images, train_labels = load_dataset(images_file=a,labels_file=b)\n",
    "test_images, test_labels = load_dataset(c, d) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           image_raw|label|\n",
      "+--------------------+-----+\n",
      "|[0.0, 0.0, 0.0, 0...|    5|\n",
      "|[0.0, 0.0, 0.0, 0...|    0|\n",
      "|[0.0, 0.0, 0.0, 0...|    4|\n",
      "|[0.0, 0.0, 0.0, 0...|    1|\n",
      "|[0.0, 0.0, 0.0, 0...|    9|\n",
      "|[0.0, 0.0, 0.0, 0...|    2|\n",
      "|[0.0, 0.0, 0.0, 0...|    1|\n",
      "|[0.0, 0.0, 0.0, 0...|    3|\n",
      "|[0.0, 0.0, 0.0, 0...|    1|\n",
      "|[0.0, 0.0, 0.0, 0...|    4|\n",
      "|[0.0, 0.0, 0.0, 0...|    3|\n",
      "|[0.0, 0.0, 0.0, 0...|    5|\n",
      "|[0.0, 0.0, 0.0, 0...|    3|\n",
      "|[0.0, 0.0, 0.0, 0...|    6|\n",
      "|[0.0, 0.0, 0.0, 0...|    1|\n",
      "|[0.0, 0.0, 0.0, 0...|    7|\n",
      "|[0.0, 0.0, 0.0, 0...|    2|\n",
      "|[0.0, 0.0, 0.0, 0...|    8|\n",
      "|[0.0, 0.0, 0.0, 0...|    6|\n",
      "|[0.0, 0.0, 0.0, 0...|    9|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "data = [(train_images[i].tolist(), int(train_labels[i])) for i in range(len(train_images))]\n",
    "schema = StructType([StructField(\"image_raw\", ArrayType(FloatType())),\n",
    "                     StructField(\"label\", LongType())])\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hdfs:///Projects/demo_deep_learning_admin000/TourData/mnist/MNIST_data/df-mnist.tfrecord.tfrecord\"\n",
    "num_partition = 4\n",
    "df.repartition(num_partition).write.format(\"tfrecords\").mode(\"overwrite\").save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
