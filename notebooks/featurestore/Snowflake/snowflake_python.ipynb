{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Predictive Analytics using Amazon SageMaker and Snowflake\n",
    "\n",
    "---\n",
    "## Background\n",
    "\n",
    "The purpose of this lab is to demonstrate the basics of building an advanced analytics solution using Amazon SageMaker on data stored in Snowflake. In this notebook we will create a customer churn analytics solution by training an XGBoost churn model, and batching churn prediction scores into a data warehouse. \n",
    "\n",
    "(Need to update) This notebook extends one of the example tutorial notebooks: [Customer Churn Prediction with XGBoost](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn_neo.ipynb). The extended learning objectives are highlighted in bold below.\n",
    "\n",
    "#### Learning Objectives \n",
    "\n",
    " - **Learn how to query ground truth data from our data warehouse into a pandas dataframe for exploration and feature engineering.**\n",
    " - Train an XGBoost model to perform churn prediction.\n",
    " - **Learn how to run a Batch Transform job to calculate churn scores in batch.**\n",
    " - Optimize your model using SageMaker Neo.\n",
    " - Upload the Churn Score results back to Snowflake to perform basic analysis. \n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "\n",
    "In summary:\n",
    " - You've built the lab environment using this CloudFormation [template](https://snowflake-corp-se-workshop.s3-us-west-1.amazonaws.com/sagemaker-snowflake-workshop-v1/sagemaker/snowflake-sagemaker-notebook-v1.1.yaml). This template installs the Snowflake python connector within your Jupyter instance.\n",
    " - You've taken note of the Snowflake credentials in the lab guide.\n",
    " - This notebook should be running in your default VPC. \n",
    " - Snowflake traffic uses port 443.\n",
    " \n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to import Python libraries required by this notebook.\n",
    "\n",
    "The IAM role arn used to give training and hosting access to your data. By default, we'll use the IAM permissions that have been allocated to your notebook instance. The role should have the permissions to access your S3 bucket, and full execution permissions on Amazon SageMaker. In practice, you could minimize the scope of requried permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set the S3 bucket and prefix that you want to use for training and model data. This bucket should be created within the same region as the Notebook Instance, training, and hosting. \n",
    "\n",
    "- Replace <<'REPLACE WITH YOUR BUCKET NAME'>> with the name of your bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "Mobile operators have historical records on which customers ultimately ended up churning and which continued using the service. We can use this historical information to construct an ML model of one mobile operator’s churn using a process called training. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model, and have the model predict whether this customer is going to churn. Of course, we expect the model to make mistakes–after all, predicting the future is tricky business! But I’ll also show how to deal with prediction errors.\n",
    "\n",
    "The dataset we use is publicly available and was mentioned in the book [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets.  In the previous steps, this dataset was loaded into the CUSTOMER_CHURN table in your Snowflake instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the connection and credentials required to connect to your Snowflake account. You'll need to modify the cell below with the appropriate **ACCOUNT** for your Snowflake trial. If you followed the lab guide instructions, the username and password below will work. \n",
    "\n",
    "**NOTE:** For Snowflake accounts in regions other than US WEST add the Region ID after a period <ACCOUNT>.<REGION ID> i.e. XYZ123456.US-EAST-1. \n",
    "\n",
    "In practice, security standards might prohibit you from providing credentials in clear text. As a best practice in production, you should utilize a service like [AWS Secrets Manager](https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html) to manage your database credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>14</td><td>application_1599768044375_0017</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://resourcemanager.service.consul:8088/proxy/application_1599768044375_0017/\">Link</a></td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8042/node/containerlogs/container_e01_1599768044375_0017_01_000001/demo_featurestore_admin000__meb10000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/snowflake/connector/options.py:40: UserWarning: You have an incompatible version of 'pyarrow' installed, please install a version that adheres to: 'pyarrow<0.18.0,>=0.17.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep('pyarrow', _installed_pyarrow.version, _expected_version)"
     ]
    }
   ],
   "source": [
    "import snowflake.connector # tested on snowflake-connector-python==2.3.1 \n",
    "# Connecting to Snowflake using the default authenticator\n",
    "ctx = snowflake.connector.connect(\n",
    "  user='HOPSWORKS',\n",
    "  password='HOPSWORKS123',\n",
    "  account='ra96958.eu-central-1',\n",
    "  warehouse='HOPSWORKS_WH',\n",
    "  database='ML_WORKSHOP',\n",
    "  schema='PUBLIC'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Explore\n",
    "\n",
    "Now we can run queries against your database. \n",
    "\n",
    "However, in practice, the data table will often contain more data than what is practical to operate on within a notebook instance, or relevant attributes are spread across multiple tables. Being able to run SQL queries and loading the data into a pandas dataframe will be helpful during the initial stages of development. Check out the Spark integration for a fully scalable solution. [Snowflake Connector for Spark](https://docs.snowflake.net/manuals/user-guide/spark-connector.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cust_id State  Account Length  Area Code     Phone Intl Plan VMail Plan  \\\n",
      "0           1    KS             128        415  382-4657        no        yes   \n",
      "1           2    OH             107        415  371-7191        no        yes   \n",
      "2           3    NJ             137        415  358-1921        no         no   \n",
      "3           4    OH              84        408  375-9999       yes         no   \n",
      "4           5    MA             121        510  355-9993        no        yes   \n",
      "...       ...   ...             ...        ...       ...       ...        ...   \n",
      "3328     3329    OK             138        510  406-5532        no        yes   \n",
      "3329     3330    AL              89        510  347-2016        no         no   \n",
      "3330     3331    ND             131        408  393-9548        no        yes   \n",
      "3331     3332    ND             122        408  395-1901        no         no   \n",
      "3332     3333    OH             136        408  392-1547       yes         no   \n",
      "\n",
      "      VMail Message  Day Mins  Day Calls  Day Charge  Eve Mins  Eve Calls  \\\n",
      "0                25     265.1        110       45.07     197.4         99   \n",
      "1                26     161.6        123       27.47     195.5        103   \n",
      "2                 0     243.4        114       41.38     121.2        110   \n",
      "3                 0     299.4         71       50.90      61.9         88   \n",
      "4                24     218.2         88       37.09     348.5        108   \n",
      "...             ...       ...        ...         ...       ...        ...   \n",
      "3328             33     155.2        139       26.38     268.3         79   \n",
      "3329              0     129.2         71       21.96     214.1         68   \n",
      "3330             33     177.1        100       30.11     194.0         85   \n",
      "3331              0     231.2        141       39.30     267.8        136   \n",
      "3332              0     183.4        103       31.18     141.9        113   \n",
      "\n",
      "      Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  \\\n",
      "0          16.78       244.7           91         11.01       10.0   \n",
      "1          16.62       254.4          103         11.45       13.7   \n",
      "2          10.30       162.6          104          7.32       12.2   \n",
      "3           5.26       196.9           89          8.86        6.6   \n",
      "4          29.62       212.6          118          9.57        7.5   \n",
      "...          ...         ...          ...           ...        ...   \n",
      "3328       22.81       186.4           71          8.39        9.7   \n",
      "3329       18.20       214.9          100          9.67       10.3   \n",
      "3330       16.49       253.4          124         11.40        5.2   \n",
      "3331       22.76       240.3          100         10.81        8.8   \n",
      "3332       12.06       200.4          122          9.02       10.4   \n",
      "\n",
      "      Intl Calls  Intl Charge  CustServ Calls  Churn?  \n",
      "0              3         2.70               1  False.  \n",
      "1              3         3.70               1  False.  \n",
      "2              5         3.29               0  False.  \n",
      "3              7         1.78               2  False.  \n",
      "4              7         2.03               3  False.  \n",
      "...          ...          ...             ...     ...  \n",
      "3328           4         2.62               3  False.  \n",
      "3329           4         2.78               5   True.  \n",
      "3330           5         1.40               1  False.  \n",
      "3331           5         2.38               1   True.  \n",
      "3332           9         2.81               2  False.  \n",
      "\n",
      "[3333 rows x 22 columns]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Query Snowflake Data\n",
    "cs=ctx.cursor()\n",
    "allrows=cs.execute(\"\"\"select Cust_ID,STATE,ACCOUNT_LENGTH,AREA_CODE,PHONE,INTL_PLAN,VMAIL_PLAN,VMAIL_MESSAGE,\n",
    "                   DAY_MINS,DAY_CALLS,DAY_CHARGE,EVE_MINS,EVE_CALLS,EVE_CHARGE,NIGHT_MINS,NIGHT_CALLS,\n",
    "                   NIGHT_CHARGE,INTL_MINS,INTL_CALLS,INTL_CHARGE,CUSTSERV_CALLS,\n",
    "                   CHURN from CUSTOMER_CHURN \"\"\").fetchall()\n",
    "\n",
    "churn = pd.DataFrame(allrows)\n",
    "churn.columns=['Cust_id','State','Account Length','Area Code','Phone','Intl Plan', 'VMail Plan', 'VMail Message','Day Mins',\n",
    "            'Day Calls', 'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls','Night Charge',\n",
    "            'Intl Mins','Intl Calls','Intl Charge','CustServ Calls', 'Churn?']\n",
    "\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 10)         # Keep the output on one page\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modern standards, it’s a relatively small dataset, with only 3,333 records, where each record uses 21 attributes to describe the profile of a customer of an unknown US mobile operator. The attributes are:\n",
    "\n",
    "- `State`: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
    "- `Account Length`: the number of days that this account has been active\n",
    "- `Area Code`: the three-digit area code of the corresponding customer’s phone number\n",
    "- `Phone`: the remaining seven-digit phone number\n",
    "- `Int’l Plan`: whether the customer has an international calling plan: yes/no\n",
    "- `VMail Plan`: whether the customer has a voice mail feature: yes/no\n",
    "- `VMail Message`: presumably the average number of voice mail messages per month\n",
    "- `Day Mins`: the total number of calling minutes used during the day\n",
    "- `Day Calls`: the total number of calls placed during the day\n",
    "- `Day Charge`: the billed cost of daytime calls\n",
    "- `Eve Mins, Eve Calls, Eve Charge`: the billed cost for calls placed during the evening\n",
    "- `Night Mins`, `Night Calls`, `Night Charge`: the billed cost for calls placed during nighttime\n",
    "- `Intl Mins`, `Intl Calls`, `Intl Charge`: the billed cost for international calls\n",
    "- `CustServ Calls`: the number of calls placed to Customer Service\n",
    "- `Churn?`: whether the customer left the service: true/false\n",
    "\n",
    "The last attribute, `Churn?`, is known as the target attribute–the attribute that we want the ML model to predict.  Because the target attribute is binary, our model will be performing binary prediction, also known as binary classification.\n",
    "\n",
    "Let's begin exploring the data:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
